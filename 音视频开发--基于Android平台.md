## 完整路线指导

[音视频完整路线](音视频完整路线.png)

## 基本认识
### 音／视频流

在音视频领域，我们把一路音／视频称为一路流。如我们小时候经常使用VCD看港片，在里边可以选择粤语或国语声音，其实就是CD视频文件中存放了两路音频流，用户可以选择其中一路进行播放。

### 容器

我们熟悉的mp4,rmvb,mkv,avi是多媒体容器文件格式（或称多媒体封装格式），**所谓容器是指将不同的数据流(视频流，音频流，字幕流等)封装在一个文件(载体)中。** 播放时各种流分别进行解码等处理后，然后输出到显示器和音响等设备进行播放。多媒体容器格式不同于编码格式，一个容器中可以封装多种编码格式的媒体流。 流封装了实际的媒体数据，如视频流，音频流和字幕流等。一般情况下，流中的数据只能使用一种编码格式。

### channel

是音频中的概念，称之为声道。在一路音频流中，可以有单声道，双声道或立体声。

### 帧率

帧率(frames per second, fps)是每秒画面刷新的次数，帧率越高视频越流畅。一般来说30fps就是可以接受的，60fps则可以明显提升交互感和逼真感，但是一般超过75fps一般就不容易察觉到有明显的流畅度提升了。

### 分辨率

分辨率表示画面的精细程度，通常用像素密度来表示，常用的单位为ppi(像素每英寸)。通常像素密度越高画面越精细，模糊程度越低。对于视频文件而言，像素密度是无法控制的(由播放器和显示设备决定)。我们通常用视频的像素数来表示它的分辨率如1080x640, 640x320等。

### 比特率

比特率(bit rate)又称**码率**，表示多媒体流**每秒输出的字节数，单位为KB/s,Kbps等**。同样的压缩算法下，比特率越高音视频的质量越好。

### 可变码率(Variable Bitrate, VBR)

指的是编码器的**输出码率可以根据输入源信号的复杂度进行自适应调整**，以在输出质量保持不变的条件下尽可能减少数据量。**VBR适用于存储，不太适用流式传输**。

### 固定码率(Constant Bitrate, CBR)

指的是编码器输出码率固定，CBR不适合存储，对于复杂内容可能没有足够码率进行编码，从而导致质量下降，同时会在简单内容部分浪费一些码率。

### 采样率

每秒钟对音频信号的采样次数，采样频率越高声音还原度越高，声音更加自然，单位是赫兹 Hz。**音频文件一般使用的采样率是 44.1kHz，也就是一秒钟采样44100次**，实验发现低于这个值就会有较明显的损失，而高于这个值人的耳朵已经很难分辨，而且增大了数字音频所占用的空间。

### 视频编码

视频流可以看做图片的序列，我们把这个序列中的一张图片称为一帧。若存储视频中所有帧则会数据量过大，不便于存储和传输。所幸统计表明大多数视频相邻帧之间的区别并不大，所以对于一段变化不大的视频，我们可以先完整编码帧A，其后的B帧只需要编码与A帧不同的部分，B帧后的C帧则只编码与B帧的差异。如此递推，将一段视频编码为一个序列。当某个图像与之前的图像变化很大无法参考前面的帧来生成，我们就结束上一个序列将该帧完整编码开始一个新的序列。

- 1）空间冗余：图像相邻像素之间有较强的相关性
- 2）时间冗余：视频序列的相邻图像之间内容相似
- 3）编码冗余：不同像素值出现的概率不同
- 4）视觉冗余：人的视觉系统对某些细节不敏感
- 5）知识冗余：规律性的结构可由先验知识和背景知识得到

## 1.解码、编码
### 简介

- -编码：编码就是将原始音频数据也就是PCM压缩的一个过程；或者是将原始的视频数据RGB或YUV压缩的一个过程。

- 解码：解码就是编码一个逆过程，比如将编码后的数据AAC解码成PCM给播放器播放；或者将编码后的H264数据解码成YUV或RGB给播放器渲染的过程

- 编解码又分为硬件编解码和软件编解码：

	- 软编软解码：使用CPU进行编码，一般是执行代码运行算法指令编码。消耗功耗大，cpu消耗性能大。兼容性强，编码可操作空间大。（压缩，剪切等等）
	- 硬编硬解码：使用非CPU进行编码，如显卡GPU、专用的DSP、FPGA、ASIC芯片等，一般是算法已经固化在芯片中。功耗低，可控性差，依赖于硬件底层实现，兼容性差，不同厂商的解码方案可能不一致。
	--------------------------------------------------------------------------------------------------
	- 硬解码效率非常高，这样不但能够减轻CPU的负担，还有着低功耗，发热少等特点。但是，由于硬解码起步比较晚，软件和驱动对他的支持度很低，往往会出现兼容性不好的问题。此外，硬解码的滤镜、字幕、画质方面都做的不够理想。

软解码需要对大量的视频信息进行运算，所以对CPU处理性能的要求非常高。巨大的运算量就会造成转换效率低，发热量高等问题。不过，软解码不需要过多的硬件支持，兼容性非常高。而且软解码拥有丰富的滤镜，字幕，画面处理优化等效果，只有你CPU够强悍，就能够实现更加出色的画面效果

- 通常我们**把解封装以后得视频流叫做裸流**，即符合H264，H265，AV1等视频编码标准编码的码流。

安卓mediaFromat下的支持解码（此处仅展示部分）
```java
public static final String MIMETYPE_VIDEO_AV1 = "video/av01";  
public static final String MIMETYPE_VIDEO_AVC = "video/avc";  //h264不同组织的命名不同罢了
public static final String MIMETYPE_VIDEO_HEVC = "video/hevc";  //h265
public static final String MIMETYPE_VIDEO_MPEG4 = "video/mp4v-es";  
public static final String MIMETYPE_VIDEO_H263 = "video/3gpp";  
public static final String MIMETYPE_VIDEO_MPEG2 = "video/mpeg2";  
public static final String MIMETYPE_VIDEO_RAW = "video/raw";
```
### NALu
编码单元
### YUV和RGB
YUV是指亮度参数和色度参量分开表示的像素格式，其中“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V”表示的则是色度（Chrominance或Chrima），作用是描述色彩及饱和度,用于指定像素的颜色。
Y：亮度分量，表示物理线性空间亮度。
U：蓝色投影。
V：红色投影。
#### 为什么要有YUV这种数据出来？
### H264
H.264/AVC 是属于MPEG-4的一种编码格式。x264是H264的一种编码实现的函数库，是一种软编。
#### 码流功能的角度
无论是解析视频文件或这通过网络传输, 其实都是一串字节序列. H264码流就是按照一定的规则组织排列的字节串.

从码流功能的角度可以分为两层:NAL层和VCL层

- **NAL 网络提取层**:负责以网络所要求的恰当的方式对数据进行打包和传送
- **VCL 视频编码层**：包括核心压缩引擎和块，宏块和片的语法级别定义，设计目标是尽可能地独立于网络进行高效的编码

  
- **SODB:(String of Data Bits,原始数据比特流)** ,长度不一定是8的倍数.它是由VCL层产生的.因为非8的倍数所以处理比较麻烦.
- **RBSP:(Raw Byte Sequence Payload,SODB+trailing bits)** .算法是在SODB最后一位补1.不按字节对齐补0. 如果补齐0,不知道在哪里结束.所以补1.如果不够8位则按位补0.
- **EBSP:(Encapsulate Byte Sequence Payload)** .就是生成压缩流之后,我们还要在每个帧之前加一个起始位.起始位一般是十六进制的0001.但是在整个编码后的数据里,可能会出来连续的2个0x00.那这样就与起始位产生了冲突.那怎么处理了? H264规范里说明如果处理2个连续的0x00,就额外增加一个0x03.这样就能预防压缩后的数据与起始位产生冲突.
- **NALU: NAL Header(1B)+EBSP**.NALU就是在EBSP的基础上加1B的网络头.



一个NALU由 固定长度的Header和RBSP组成

![[20200702230943756.png]]

从图一中我们看到SPS,PPS。这是符合H.264码流中第一个NALU是SPS，第二个NALU是PPS。SPS和PPS包含了

初始化H.264解码器所需要的信息参数。

- SPS 序列参数集：包含的是针对一连续编码视频序列的参数，如标识符seq_parameter_set_id、帧数及POC的约束、参考帧数目、解码图像尺寸和帧场编码模式选择标识等。

- PPS 图像参数集：对应的是一个序列中某一副图像或者某几幅图像，参数如标识符pic_parameter_set_id、可选的seq_parameter_set_id、熵编码模式选择标识、片组数目、初始量化参数和去方块滤波系数调整标识等。

通过以上可知，如果H.264码流中无PPS或者SPS的话，解码器是无法解析码流数据，自然是无法播放。


![[v2-cf08e64260030a99c2a98306b88cb328_720w.png]]
#### 1.2. I帧数 B帧 P帧


H264是目前流行的一种视频编码算法，它定义了三种帧：
- I帧：帧内编码帧，大多数情况下I帧就是关键帧，就是一个完整帧，无需任何辅助就能独立完整显示的画面。

- B帧：帧是双向预测帧。参考前后图像帧编码生成。需要前面的 I/P 帧或者后面的 P 帧来协助形成一个画面。

- P帧：前向预测编码帧。是一个非完整帧，通过参考前面的I帧或P帧生成画面。

#### 解码流程
![[20191209142105513.webp]]
### H265



### H264/H265有什么区别？


### Non-B-Frame技术(无b帧技术)


### **视频解码器/解码器**
#### 1.MediaCodec
MediaCodec是Android平台提供的一个底层的音视频编解码框架，它是安卓底层多媒体基础框架的重要组成部分。它经常和 MediaExtractor, MediaSync, MediaMuxer, MediaCrypto, MediaDrm, Image, Surface, AudioTrack一起使用。解码的作用，就是将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。反之，编码的作用，就是将非压缩的视频/音频原始数据转为视频/音频压缩编码数据。
**一般默认是硬解码，但是需要硬件支持，如果没有就只能软解**

编码大致流程：设置编码参数---创建编码器----创建混合器MediaMuxer（封装成盒子（mp4等等））----开始编码
#### 2.FFmpeg

|   |   |
|---|---|
|avcodec|音视频编解码核心库|
|avformat|音视频容器格式的封装和解析|
|avutil|核心工具库|
|swscal|图像格式转换的模块|
|swresampel|音频重采样|
|avfilter|音视频滤镜库 如视频加水印、音频变声|
|avdevice|输入输出设备库，提供设备数据的输入与输出|

源码结构：
- libavcodec:提供了一个通用的编码/解码框架包含多种音解码器和编码器，视频和字幕流，和几个比特流过滤器。共享体系结构提供了各种各样的服务，从比特流I/O到DSP优化，使得它适合于实现健壮和快速的编解码器，以及用于实验。

- libformat:提供了视频的复用和多路处理功能。实现了流媒体协议（udp、rtp、rtmp、rtsp等），媒体容器（mp4、AVI、Flv等）和基本的I/O访问。

- libavutil:是一个实用程序库，以帮助便携式多媒体编程。它包含了安全的移动字符串函数，随机数生成器，数据结构，附加数学功能，加密和多媒体相关的功能（如枚举的像素采样格式）。它并不是libavcodec和libav必备的库

- libavdevice:抓取和绘制多种多媒体输入/输出设备提供了一个通用的框架，支持多种输入和输出设备，包括video4linux2 vfw dshow ALSA。

- libavfilter:是一个通用的音视频后处理库。例如噪音处理

- libswcale:执行高度优化的图像缩放和颜色的像素格式转换操作。  
具体来说，这个库执行以下操作：  
缩放：是改变视频大小的过程。几种缩放选项和算法都可以。这通常是一个有损过程。  
像素格式转换：是图像的图像格式和色彩空间转换的过程，例如从平面yuv420p为RGB24包装。它还处理包装转换，即从填充布局（所有属于同一缓冲区内的不同平面的像素）转换为平面布局（所有属于同一平面的样本都存储在专用缓冲区或“平面”）中。  
这通常是在源和目标颜色不同的有损压缩。

- libswresample:实现音频的重采样和混音，根据平台做了优化（neon等）。  
该libswresample库进行高度优化的音频采样，rematrixing和采样格式转换操作。  
重采样：是改变音频速率，例如从44100Hz的高采样率到8000Hz的过程。从高至低采样率的音频转换是一种有损的过程。几个重采样选项和算法是可用的。  
格式转换：是将样品的类型，例如从16位有符号的样本为无符号的8位或浮样品的过程。它还处理包装的转换，从包装的布局传递时，以平面布局（属于交织在相同缓冲液不同的信道的所有样品）（属于存储在专用缓冲区或“平面”相同的信道的所有样品）。  
Rematrixing：是改变频道布局，例如从立体声到单声道的过程。当输入通道不能被映射到输出数据流，该方法是有损耗的，因为它涉及到不同的增益因子和混合。  
其他各种音频转换（如拉伸和填充）通过专用的选项启用。


链接：https://www.jianshu.com/p/9e97bb5b1ce5  

##### 2.1 FFmpeg解码

![[559adc64edfa49809396ba6258df8bac~tplv-k3u1fbpfcp-zoom-in-crop-mark 4536 0 0 0.webp]]
##### 2.1 在Android中使用ffmpeg播放视频
![[10190436-0bd5b374ce97f20e.webp]]
主要流程是下面几点

- java层将Surface传递给native层
- 获取ANativeWindow对象
- 将显示数据写到ANativeWindow的buffer中，注意需要将显示的数据格式转换成ANativeWindow设置的数据格式
- 释放ANativeWindow


##### 3 支持Mediacodec
FFmpeg 在 3.1 版本之后支持调用平台硬件进行解码，也就是说可以通过 FFmpeg 的 C 代码去调用 Android 上的 MediaCodec 。
在官网上有对应说明，地址如下：
​https://trac.ffmpeg.org/wiki/HWAccelIntro​​
它的编译有很多开关选项，要确保打开了 mediacodec 相关的选项，具体如下：
--enable-mediacodec
--enable-decoder=h264_mediacodec
--enable-decoder=hevc_mediacodec
--enable-decoder=mpeg4_mediacodec
--enable-hwaccel=h264_mediacodec

可以看出 mediacodec 支持的编码格式有 h264、hevc、mpeg4 三种可选，不在范围内的就还是考虑软解吧。

##### 4 FFmpeg+OpenGL ES/OpenSL ES

#### 如何给 FFmpeg 添加自定义 Codec 编码器？

简单概况一下：

- 首先通过 avformat_open_input 方法打开文件，得到 AVFormatContext 。
 - 然后通过 avformat_find_stream_info 查找文件的视频流信息。
- 得到文件相关信息和视频流信息，主要还是为了得到编码格式信息，然后好找到对应的解码器。也可以通过 avcodec_find_decoder_by_name 方法直接找具体的解码器。
- 有了解码器就可以创建解码上下文 AVCodecContext，并通过 avcodec_open2 方法打开解码器
- 然后通过 av_read_frame 读取文件的内容好进行下一步的解码。
- 接下来就是熟悉的 avcodec_send_packet 发送给解码器，avcodec_receive_frame 从解码器取回解码后的数据。

附1：FFmpeg 调用 Android MediaCodec 进行硬解码（附源码）
https://blog.51cto.com/u_12127193/5739432
附2： FFmpeg 调用 MediaCodec 硬解码到 Surface 上
https://blog.51cto.com/u_12127193/5739376?articleABtest=0

问题1：有了上层MediaCodec，为什么还要native层解决方案？
回答：由于我们的数据流向是编码前YV12/NV21/NV12/I420/RGB24/RGBA32/RGB565等数据类型，底层统一处理后，实现H264、HEVC的编码，减少了上下层之间的交互，效率更高，


### 音频解码/编码

基础知识并使用AudioTrack、OpenSL ES渲染PCM数据

#### PCM
PCM是声音从模拟信号转为数字信号的技术。
通常所说的音频的裸数据就是 PCM (Pulse Code Modulation) 数据。
描述一段 PCM 数据一般需要以下几个概念：
- 量化格式(sampleFormat)
- 采样率（sampleRate）
- 声道数 (channel) 
以 CD 的音质为例：量化格式为 16 bit （2 byte）,采样率 44100 ，声道数为 2 ，这些信息就描述了 CD 的音质。而对于声音的格式，还有一个概念用来描述它的大小，称为数据比特率，即 1s 时间内的比特数目，它用于衡量音频数据单位时间内的容量大小。而对于 CD 音质的数据，比特率为多少呢？ 计算如下:

	44100 * 16 * 2 = 1378.125 kbps

那么在一分钟里，这类 CD 音质的数据需要占据多大的存储空间呢？计算如下:

	1378.125 * 60 / 8 / 1024 = 10.09 MB
## 4. EXOPlayer
### 1 ExoPlayer优缺点  
ExoPlayer是谷歌开源的一个应用级的音视频播放器。ExoPlayer 支持基于 HTTP 的动态自适应流 (DASH)、SmoothStreaming 和通用加密、以及可以很好的支持播放队列、播放源的无缝切换等功能。它采用易于自定义和扩展的设计。  
内部的实现也是调用了低层API，比如：MediaCodec、AudioTrack等

画张表格来对比下ExoPlayer和MediaPlayer，更直观的了解

![](https://pic3.zhimg.com/80/v2-48fad76b5320f7378c3900cc60f21e1e_720w.jpg)

**状态机**  
在看ExoPlayer的状态机之前，我们先看下MeidaPlayer的状态机

![](v2-9847d0d00fa711ea28ed0a9476e05cd5_720w.webp)
可以看到MediaPlayer的状态比较多，使用时如果在不当的位置触发了不匹配的操作，直接会崩溃。

## 5.ijkplayer
ijkPlayer是BiliBili公司维护的一个开源工程，**基于ffmpeg开发的一个播放器软件**，支持Android和iOS平台，整个ijkplayer就是以ffplay为基础，如果只是使用它进行播放，集成也较为简单，使用也和MediaPlayer差不多，但是要定制化需求，就有一定的门槛高度。

ijkplayer是一款跨平台的播放器，支持Android与iOS端，核心部分基于ffmpeg，支持Android的mediacodec硬解与iOS的videotoolbox硬解，视频图像采用OpenGL进行渲染。许多主流播放器都使用ijkplayer作为播放方案。接下来我们从核心播放流程、内核架构、时序图、状态机、播放器整体架构进行详细分析。

# 5. 流媒体传输协议

流媒体技术需要解决的问题：

- 1.允许客户端在不下载完整文件的时候即可以开始播放视频；

- 2.允许客户端从完整内容的任何位置开始播放（不包括视频直播）；

- 3.针对视频直播，允许客户端从任意时间开始观看频道内容；

- 4.允许在客户的带宽条件和客户端的硬件条件下播放；

- 5.提供相对平稳的传输速度，以便用户基本流畅地完成播放。

并伴随两个衍生技术：

- 1.支持CDN传输，以提供服务扩展能力和较好的用户访问质量。

- 2.支持视频内容的加密，避免版权内容被人依靠复制传播牟利

RTSP和RTMP是基于会话的流媒体协议，HLS(Http Live Streaming)、HDS(Http Dynamic Streaming)和Smooth Streaming(HSS)则是基于HTTP的协议。

## ## RTSP协议、RTP、RTCP、SDP
### RTSP

RTSP通常与RTP和RTCP协议共同使用，其中RTSP是服务端与客户端间的双向协议，**它不负责传输音视频数据，而是用来控制多个音视频流。**
它基于TCP建立会话，请求结构与HTTP1.1类似。RTSP协议支持重定向，即将播放会话重定向，让其他服务器提供服务。协议也可选择不同的传输通道，例如基于TCP、UDP以及组播UDP传输RTP协议。

但是需要服务器支持
![[1cc6170f1077408699da574b37e2bcf0.png]]

RTSP通过不同的命令构建完整的控制会话，**同时依赖RTP和RTCP或其他协议传输音视频本身的数据。**
### RTP
RTP是Real-time Transport Protocol的简称

**RTP协议将不同编码和封装格式的音视频数据进行再封装，加上RTP头形成RTP包**，再行发送，RTP包头内的重要信息包括**序列号**、**时间戳**、**负载格式**等。

RTP协议提供**抖动补偿**和**数据无序到达**的检测机制。

### RTCP
RTCP即RTP Control Protocol，协议本身并不发送数据，而是收集客户端的统计信息，包括**传输字节数**、**传输分组数**、**丢失分组数**、**网络延迟**、**Jitter**（抖动）等，服务器可籍此**改变码率**或**调节数据**发送速度。

### 总结
一次典型的播放过程将在客户端和服务器间建立**5个不同的Session：一路**RTSP**的Session、两路**RTP**的Session（音频和视频各一）以及两路**RTCP Session（分别对应两路RTP Session），占用5个不同的端口（RTSP协议的默认端口是554，RTP及RTCP的端口由SETUP命令指定）**
```mermaid
graph LR
  A[RTSP控制其他传输流]-->B[RTP传输视频]
  A-->C[RTP音频]
  B-->D[RTCP统计视频信息]
  C-->E[RTCP统计音频信息]
  ```


RTSP协议支持重定向，即将播放会话重定向，让其他服务器提供服务。协议也可选择不同的传输通道，例如基于TCP、UDP以及组播UDP传输RTP协议

允许双向交换信息，使用多达5个会话交换数据的RTSP方式流媒体传输，很像是在双向多车道的马路上奔驰，无疑很大程度上解决了交通的问题，但“成也萧何，败也萧何”，多车道对资源的占用或许就是被后来的RTMP等协议挤占的根源。

## ## RTMP实时消息传输协议

RTMP（Real-Time Messaging Protocol，即实时消息传输协议）。RTMP是基于**TCP**的**可靠传输层协议**，仅需一个会话即可相互通信，与RTSP协议相比，如同由轨道支撑的高速铁路，虽然形式略重，但效率高、速度快。

RTMP并非一个单独协议，而是由多个相关协议组成的协议族。

- 1.RTMP，默认使用TCP端口1935的明文协议。

- 2.RTMPS，即通过TLS/SSL连接传输的RTMP。

- 3.RTMPE，使用Adobe私有安全机制加密的RTMP。

- 4.RTMPT，使用HTTP封装的RTMP、RTMPS或RTMPE，利于穿透防火墙。

- 5.RTMPFP，使用UDP的RTMP，允许用户进行P2P连接。

将音视频及其他数据封装为RTMP Message发送，而在实际传输时会进一步将Message划分为带有Message ID的Chunk。每个Chunk可以携带一个Message。但更多情况下，**一个Message将由多个Chunk承载，直到客户端接收后将其还原。**
![[91d4b01d0e5148dcacdde9a0277d0131.png]]
  
RTMP协议支持Push和Pull两种模式，Pull即是普遍的客户端根据URL进行播放的方式，而Push基于RTMP的视频直播，其握手顺序和createStream步骤类似，由客户端使用Publish命令而非Play命令，发起自客户端到服务端的推送。

当握手完毕后，连接将被复用来发送一个或多个Chunk流，Chunk的默认大小为128字节，由客户端和服务器设置其可以接受的Chunk大小（可以动态调整），Chunk承载的Message类型不同，其Message Header亦有多种，不同的fmt取值将用以鉴别不同的Chunk类型。


![[v2-b7022a92221cfb9905ed10252102616a_720w.jpg]]

## HLS、HDS、HSS

RTSP和RTMP是基于会话的流媒体协议，HLS(Http Live Streaming)、HDS(Http Dynamic Streaming)和Smooth Streaming(HSS)则是基于HTTP的协议。

### HLS
这个协议的产生是为了解决RTMP协议存在的一些问题。 比如RTMP协议不使用标准的HTTP接口传输数据，所以在一些特殊的网络环境下可能被防火墙屏蔽掉

简介协议的原理是将点播所需的多媒体文件或直播的视频流，切分成许多小块的文件，让客户端基于HTTP进行下载，**当播放时，客户端需下载包含metadata信息的M3U8文件（也称作索引文件、Playlist或Manifest文件），根据M3U8文件的内容，同时依据网络条件选择不同码率的内容进行播放。**

HLS支持如下音视频格式，首先是MPEG2-TS或fMP4（即Fragmented MP4）格式封装的切片文件（Segment）。其次，它支持打包的纯音频格式，包括以ADTS头封装的AAC帧、MP3、AC3和EAC3格式，对字幕，它只支持WebVTT格式

视频的封装格式是TS。(MPEG2-TS)

l 视频的编码格式为H264,音频编码格式为MP3、AAC或者AC-3。

l 除了TS视频文件本身，还定义了用来控制播放的m3u8文件（文本文件）。

HLS协议的劣势（相比RTMP协议）  
HLS也有一些无法跨越的坑，比如采用HLS协议直播的视频延迟时间无法下到10秒以下，而RTMP协议的延迟最低可以到3、4秒左右。所以说对直播延迟比较敏感的服务请慎用HLS。

# WebRTC（Web Real-Time Communications）


## 录制视频的方式

在Android系统当中，如果需要一台Android设备来获取到一个MP4这样的视频文件的话，主流的方式一共与三种：MediaRecorder、MediaCodec+MediaMuxer、FFmpeg。

### MediaRecorder
是Android系统直接提供给我们的录制类，用于录制音频和视频的一个类，简单方便，不需要理会中间录制过程，结束录制后可以直接得到音频文件进行播放，录制的音频文件是经过压缩的，需要设置编码器，录制的音频文件可以用系统自带的播放器播放。

优点：大部分以及集成，直接调用相关接口即可，代码量小，简单稳定；

缺点：无法实时处理音频；输出的音频格式不是很多。

### MediaCodec+MediaMuxer
MediaCodec 与 MediaMuxer结合使用同样能够实现录制的功能。MediaCodec是Android提供的编解码类,MediaMuxer则是复用类(生成视频文件)。从易用性的角度上来说肯定不如MediaRecorder，但是允许我们进行更加灵活的操作，比如需要给录制的视频添加水印等各种效果。

优点: 与MediaRecorder一样低功耗速度快，并且更加灵活

缺点: 支持的格式有限，兼容性问题

### FFmpeg 
FFmpeg（Fast forword mpeg，音视频转换器）是一个开源免费跨平台的视频和音频流方案，它提供了录制/音视频编解码、转换以及流化音视频的完整解决方案。主要的作用在于对多媒体数据进行解协议、解封装、解码以及转码等操作

优点：格式支持非常的强，十分的灵活，功能强大，兼容性好；

缺点：C语言些的音视频编解码程序，使用起来不是很方便。

# 5.直播设计

![[202211181953255323954.png]]