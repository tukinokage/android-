# 用户态、内核态是什么

大家在学习 **操作系统原理、多线程** 时肯定听说过这个：`系统中断会造成 CPU 从用户态 --> 内核态 的切换` ，虽然也会有一些解释，但是我想应该有很多人其实不明白 用户态、内核态到底是个什么东东

用户态、内核态是什么呢？其实不是多复杂。用户态、内核态的概念就是指 CPU 指令权限的区别，你要在应用程序中读写 IO，那么就必然会用到 `ring 0` 级别的 CPU 指令，而应用程序的 CPU 指令权限只有 `ring 3`，那么就必须到拥有 `ring0 权限的系统内核` 中去执行这行代码，必然会造成 CPU 从 用户态到内核态 的切换。其表现形式是：代码会从应用程序所在的 用户线程 切换到 内核中的 内核线程 去执行，恩，就是这么回事
# 线程

是操作系统中调度的最小单位，

- 新建（New）：线程刚被创建，尚未启动。
- 运行（Runnable）：线程可以运行或正在运行，JVM 线程调度器负责调度线程交替执行。
- 同步阻塞（Blocked）：线程在等待获取锁以进入同步区域时出现阻塞。
- 等待阻塞（Waiting）：线程等待其他线程发出通知。
- 超时等待（Timed Waiting）：线程等待其他线程触发某个条件，或者达到一个时间限制。
- 终止（Terminated）：线程执行完成或因为异常而终止。

> (一). **等待阻塞**：运行(running)的线程执行**o.wait()方法**，JVM会把该线程放入等待队列(waitting queue)中。 
> (二). **同步阻塞**：运行(running)的线程在获取对象的同步锁时，若该同步锁**被别的线程占用**，则JVM会把该线程放入锁池(lock pool)中。 
> (三). **其他阻塞**：运行(running)的线程执行**Thread.sleep(long ms)或t.join(**)方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。

5. **死亡(DEAD)**：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。
### 线程中断

一般情况下，线程不执行完任务不会退出，但是在有些场景下，==我们需要手动控制线程中断结束任务，Java中有提供线程中断机制相关的Api,每个线程都一个状态位用于标识当前线程对象是否是中断状态==

|方法|简介|
| ---- | ----|
|public boolean isInterrupted()| //判断中断标识位是否是true，不会改变标识位  |
|public void interrupt()|  //将中断标识位设置为true|  
|public static boolean interrupted() |//判断当前线程是否被中断，并且该方法调用结束的时候会清空中断标识位|

需要注意的是interrupt（）方法并不会真的中断线程，==它只是将中断标识位设置为true,具体是否要中断由程序来判断==，如下，只要线程中断标识位为false,也就是没有中断就一直执行线程方法
```java
new Thread(new Runnable(){
	while(!Thread.currentThread().isInterrupted()){  
	
	//执行线程方法

} ).start();
```
#### 那么怎么做比较好？
1. 使用退出标志，使线程正常退出，也就是当 run() 方法完成后线程中止。这种方法需要在循环中检查标志位是否为 true，如果为 false，则跳出循环，结束线程。
    
2. 使用 stop() 方法强行终止线程，但是不推荐使用这个方法，==该方法已被弃用==。这个方法会导致一些清理性的工作得不到完成，如文件，数据库等的关闭，以及数据不一致的问题。
    
3. 使用 interrupt() 方法中断线程。这个方法会在当前线程中打一个停止的标记，并不是真的停止线程。因此需要在线程中判断是否被中断，并增加相应的中断处理代码。==如果线程在 sleep() 或 wait() 等操作时被中断，会抛出 InterruptedException 异常。==
### JVM线程的实现
常情况下，JVM会把它们映射到底层操作系统的不同内核线程上。但是，在某些场景下，由于不同的操作系统、JVM实现或架构设计原因，一个内核线程可能被多个Java线程共享。现在的JVM已经没有这样子的了。

内核空间的内核线程和JVM的线程的调度图：
![[20160712204159672.jpg]]
提前解释：轻量级进程（LWP）-》在用户线程和内核线程之间的一种接口，存活在用户态，负责内核线程与用户线程调度

主要是三种方式：
1. 通过内核线程实现（内核綫程也就是由操作系統内核直接操支持的綫程，切换）
	1. 一般一个内核线程对应一个轻量级进程，一个进程可以有多个轻量级进程。
	2. 基于内核线程实现，因此各线程操作等需要系统调用，系统调用代价高，需要在`用户态`和`内核态`来回切换，其次，`每个轻量级进程都需要一个内核线程的支持，因此轻量级进程要消耗一定的内核资源`，如内核线程的栈空间，因此一个系统`支持轻量级进程的数量是有限的`(这个很好理解)
		![[v2-7784c782c0bc9ba92c19163a8c8796eb_720w.jpg]]

2. 使用用户线程实现（用戶綫程的建立、同步、銷毀都是在用戶態）
	1. 广义上，内核线程以外，就是用户线程。轻量级进程也算用户线程，但轻量级进程的实现始终是建立在内核上的，许多操作都要进行系统调度，效率会受到限制。
	2. 狭义上，用户线程指完全建立在用户空间的线程库上。
	3. `这种线程不需要切换内核态，效率非常高且低消耗`，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型。
3. 使用用户线程 + 轻量级进程混合實現（輕量級进程就是通常意義上讲的线程，内核的特殊接口）
	1. 通过建立轻量级进程，可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低整个进程被完全阻塞的风险。用户线程与轻量级进程比例是N:M。
	![[v2-335f83cb7feca13f00a91be79b314f13_720w.webp]]
#### java的綫程實現
主要采用的第三種, Sun JDK,它的Windows版本和Linux版本都使用一对一的线程模型实现，**一条Java线程就映射到一条轻量级进程之中。**
#### **Java线程调度**

事先解释: **什么是cpu中断？**
中断是计算机用于硬件和软件之间一种通信机制，发生中断的时候，cpu会把会暂停正在执行的任务，保存当前工作环境（上下文），然后转去处理中断服务程序。



线程调度是指系统为线程分配处理器使用权的过程，主要调度方式分两种，分别是`协同式线程调度`和`抢占式线程调度`。

- 协同式线程调度，也就是运行完通知
	- 线程执行时间由线程本身来控制，==线程把自己的工作执行完之后，要主动通知系统切换到另外一个线程上==。最大好处是实现简单，且切换操作对线程自己是可知的，没啥线程同步问题。坏处是线程执行时间不可控制，==如果一个线程有问题，可能一直阻塞在那里。==

- 抢占式调度，也就是==按照任务来分配cpu时间片==（如何分配？看操作系统机制），没执行完等着下次中断。
	- ==每个线程将由系统来分配执行时间==，线程的切换不由线程本身来决定（Java中，Thread.yield()可以让出执行时间，但无法获取执行时间）。线程执行时间系统可控，也不会有一个线程导致整个进程阻塞。==靠cpu中断来获取cpu时间片，但是切换线程上下文需要消耗时间。==

时间片轮转调度是抢占式调度的一个实例，但并非所有抢占式调度都是时间片轮转调度。也有其他类型的抢占式调度策略。诸如优先级调度，它根据任务的优先级分配CPU时间，而不是轮流分配时间片。

`Java线程调度就是抢占式调度。``

`希望系统能给某些线程多分配一些时间，给一些线程少分配一些时间，可以通过设置线程优先级来完成`。Java语言一共10个级别的线程优先级（Thread.MIN_PRIORITY至Thread.MAX_PRIORITY），在两线程同时处于ready状态时，优先级越高的线程越容易被系统选择执行。但优先级并不是很靠谱，因为Java线程是通过映射到系统的原生线程上来实现的，所以`线程调度最终还是取决于操作系统`。
### 线程上下文切换相关概念

 上下文切换 (context switch) , 其实际含义是任务切换, 或者CPU寄存器切换。当多任务内核决定运行另外的任务时, 它保存正在运行任务的当前状态, 也就是CPU寄存器中的全部内容。这些内容被保存在任务自己的堆栈中, 入栈工作完成后就把下一个将要运行的任务的当前状况从该任务的栈中重新装入CPU寄存器, 并开始下一个任务的运行, 这一过程就是context switch。

	线程上下文是指某一时间点 CPU 寄存器和程序计数器的内容，CPU通过时间片分配算法，也就是时间片轮转来循环执行任务（线程），因为时间片非常短，所以CPU通过不停地切换线程执行。 

时间片（timeslice）又称为“量子（quantum）”或“处理器片（processor slice）”是分时操作系统分配给每个正在运行的进程微观上的一段CPU时间（在抢占内核中是：从进程开始运行直到被抢占的时间）。现代操作系统（如：Windows、Linux、Mac OS X等）允许同时运行多个进程 —— 例如，你可以在打开音乐播放器听音乐的同时用浏览器浏览网页并下载文件。事实上，虽然一台计算机通常可能有多个CPU，但是同一个CPU永远不可能真正地同时运行多个任务。在只考虑一个CPU的情况下，这些进程“看起来像”同时运行的，实则是利用了时间片轮转的方式轮番穿插地运行，由于时间片通常很短（在Linux上为5ms－800ms），而这一行为用户不会感觉到。
#### 线程上下文切换带来的问题

上下文切换会导致额外的开销，常常表现为高并发执行时速度会慢串行，因此减少上下文切换次数便可以提高多线程程序的运行效率。

    直接消耗：指的是CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉
    间接消耗：指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小
### java线程分类
 Java线程分为两类：`User Thread（常规线程/用户线程/非守护线程）` 和` Daemon Thread(守护线程)``

守护线程和非守护线程的区别：

- 守护线程：守护整个JVM中的所有非守护线程。講人話，你程序要正常運行必須要有一個綫程在運行。

- 守护线程的生命周期：只要当前JVM中还有一个非守护线程没有结束，守护线程就全部工作；直到所有非守护线程全部结束后，守护线程随着JVM一同结束；

- 守护线程最典型的例子：GC（垃圾回收器）



## JVM的生命周期：
- 当前JVM所有非守护线程执行完毕后，JVM不会管守护线程，会调用exit()方法直接退出；

注意：
- 1、通过thread.setDaemon(true)来设置一个线程为守护线程；isDaemon()方法判断是否为守护线程；

- 2、设置setDaemon()方法一定要在一个线程被start()之前设置，否则会抛IllegalThreadStatusException异常。不能把运行中的常规线程设为守护线程；

- 3、守护线程中产生的线程也是守护线程；

- 4、守护线程不能用于访问固有资源；（比如读写操作或者计算逻辑）

- 5、Java自带的多线程框架，如ExecutorService，会将守护线程转换为用户线程。所以要使用后台线程就不能用Java的线程池；

  

守护线程的意义及应用场景：

当主线程结束时，其余的子线程自动关闭。这就免去了继续关闭子线程的麻烦。


## java实现Callable重写call方法

实现Callable和实现Runnable类似，但是功能更强大，具体表现在

- a.可以在任务结束后提供一个返回值，Runnable不行
    
- b.call方法可以抛出异常，Runnable的run方法不行
    
- c.可以通过运行Callable得到的Fulture对象监听目标线程调用call方法的结果，得到返回值，（fulture.get(),调用后会阻塞，直到获取到返回值）

当我们提交任务时，`submit()`方法返回一个与任务关联的`Future`对象。我们可以用`futureResult.get()`方法来获取任务结果。请注意，调用`get()`会导致调用线程阻塞，直到任务完成为止。

## 等待唤醒机制
## Wait
调用锁对象的wait()方法后，==线程会释放掉他所占用的锁，从而使线程所在对象中的其他synchronized数据可以被其他线程使用。==
==并且会阻塞当前线程，释放线程资源，进入等待阻塞状态==


对象被调用wait之后的线程处于一个wait set中。

==`以上过程都必须在锁中进行`==
```java
Object lock1 = new Object();
synchronized (lock1){  
    System.out.println("lock1释放");  
    lock1.wait();  
    System.out.println("lock1返回");  
}
```
## noftify和notifyall

两个概念：

- 等待池：假设一个线程A调用了某个对象的==wait()方法==，==线程A就会释放该对象的锁后，进入到了该对象的等待池==，等待池中的线程不会去竞争该对象的锁。
- 锁池：只有获取了对象的锁，线程才能执行对象的 synchronized 代码，对象的锁每次只有一个线程可以获得，其他线程只能在锁池中等待

notify：==随机唤醒等待池中的一个线程==，
	具体唤醒哪个线程是不确定的，==取决于线程调度机制==。在Java中，线程调度采用的是协同多任务（cooperative multitasking）方式，也就是说线程会主动放弃CPU的执行时间，以便其他线程可以运行。

notifyAll:==唤醒等待池中的所有线程，进入锁池==



都是object对象的默认方法。

```java
//要点1，都是在syn代码块里
//要点2，都是同一个锁对象
Object lock;

//thread 1:

//悲观锁
//非公平锁
//可重入锁
synchronized(lock){

    try{
        a.wait();//进入阻塞状态
        sout("thread 1");
    }catch(InterruptedException e){
        
    }
}

//thread 2
synchronized(lock){
    try{
        Thread.sleep(3000);
       
    }catch(InterruptedExcetion e){
        
    }
    lock.notify();//随机唤醒lock的等待池中的一个线程
}
```


## 问题
1. notify是随机唤醒等待池的一个线程，那么如果我们要实现一定顺序唤醒应该怎么做？
- 通过thread.join()，它们内部也是通过wait来阻塞运行的
- 自己把控好wait和notify的先后顺序
- 通过信号量控制
- 使用CountDownLatch（AQS实现，本质上也是基于信号量实现的）
- CyclicBarrier
## 
# 锁

java中的锁标志存在于对象头中，至于实现机制不同锁是不同的。 



## 锁的四种状态

无锁：没有竞争或者是通过其他方式来限制（例如volatile关键字，CAS）

偏向锁：只有一个线程占用了锁的时候，线程便处于该状态

轻量级锁：多个线程竞争时升级为该锁

重量级锁：等待的线程超过一个，升级为重量级锁



## 乐观锁和悲观锁

这是锁的主要分类

**乐观锁（无锁**）： 总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，基于CAS,  **如java.util.concurrent.atomic下的原子类**

**悲观锁：synchronized**，总是假设拿数据的时候被人会修改数据, 这样当任何人要或取数据的时候只能阻塞直到取得锁。悲观锁大部分基于**AQS(抽象的队列同步器)**实现。AQS定义了一套**多线程访问共享资源的同步框架**

## 公平锁和非公平锁

公平锁：==根据申请锁的先后顺序来获得锁==

非公平锁：多个线程获得锁的先后顺序不是按照申请先后顺序。有可能造成**优先级反转**或**饥饿现象**。==效率比公平锁高==



要点：lock默认创建非公平锁



```java
Lock lock = new ReetentLock();//默认参数false，非公平锁

Lock lock = new ReetentLock(true);//true为公平锁

lock.lock();
/*
需要上锁的代码块
*/
lock.unlock();
```

## 独占锁
独占锁（Exclusive Lock）是一种同步原语，==它在同一时刻只允许一个线程访问共享资源==。独占锁的设计目的是为了保证资源在多线程环境下的互斥访问，防止出现并发问题，如数据竞争（Data Race）和不一致（Inconsistency）等。

在 Java 中，synchronized 关键字及 java.util.concurrent.locks 包中的 ReentrantLock 类都是独占锁的实现。

synchronized 关键字可用于修饰方法或代码块，它的作用范围是同步的对象。一个线程进入 synchronized 声明的方法或代码块时，其他线程将无法获取该对象的锁来访问同步的代码，必须等待前一个线程释放锁。

ReentrantLock ==是一种可重入独占锁==。比起 synchronized 关键字，ReentrantLock 提供了更多的功能，如公平锁、非公平锁、可中断锁定、尝试获取锁等。可重入特性表示同一个线程可以多次获取同一把锁，而不会导致死锁。

在实现独占锁时，可以使用 Java 中的 AQS（AbstractQueuedSynchronizer）类。针对独占锁，需要实现 `tryAcquire()` 和 `tryRelease()` 方法。AQS 提供了一组同步原语，使得开发者可以高效地构建自己的独占锁实现。
## 共享锁
共享锁（Shared Lock）是一种允许多个线程同时==访问共享资源的同步原语==。与独占锁（Exclusive Lock）相反，独占锁在同一时刻只允许一个线程访问共享资源。共享锁在并发编程中很有用，特别是当多个线程需要对数据进行读取操作时，==它们可以并行读取数据==，从而提高程序的性能。

共享锁一般在以下场景中使用：

1. 读多写少的场景：当有多个线程需要频繁读取共享资源，但很少需要对其进行修改时，共享锁能够显著提高程序的性能。
    
2. 数据一致性保证：在批量修改数据时，为了保证某一个时刻所有线程读到的数据是一致的，可以使用共享锁来限制某一段时间内只有一个线程能够修改数据，其他线程只能读数据。
    

	一个典型的==共享锁实现是读写锁（ReadWriteLock==），它将对共享资源的访问区分为读操作和写操作。允许多个线程同时进行读操作，但写操作是独占的，即同一时间只能有一个线程进行写操作。这种锁适用于读操作频繁但写操作较少的场景。

Java 并发工具包（java.util.concurrent.locks）中的 ReentrantReadWriteLock 就是读写锁的一个实现。
==ReentrantReadWriteLock 提供了两种锁：读锁和写锁。
	读锁是共享锁，允许多个线程同时进行读操作。
	写锁是独占锁，确保在写操作时，其他线程不能读取或修改数据==。

在实现共享锁时，可以使用 Java 中的 AQS（AbstractQueuedSynchronizer）类，针对共享锁需要实现 `tryAcquireShared()` 和 `tryReleaseShared()` 方法。利用 AQS 提供的同步原语，使得开发者可以高效地构建自己的共享锁实现。

## 可重入锁 / 不可重入锁

#### 可重入锁

广义上的可重入锁指的是可重复可递归调用的锁，在外层使用锁之后，在内层仍然可以使用，并且不发生死锁（前提得是同一个对象或者class），这样的锁就叫做可重入锁。==ReentrantLock和synchronized都是可重入锁==

```
synchronized void setA() throws Exception{
 Thread.sleep(1000);
 setB();
}
synchronized void setB() throws Exception{
 Thread.sleep(1000);
}
```

上面的代码就是一个可重入锁的一个特点，如果不是可重入锁的话，setB可能不会被当前线程执行，可能造成死锁。

#### **不可重入锁**

==不可重入锁，与可重入锁相反，不可递归调用，递归调用就发生死锁==。看到一个经典的讲解，使用自旋锁来模拟一个不可重入锁，代码如下：如果递归就一直无法释放

```java
import java.util.concurrent.atomic.AtomicReference;
public class UnreentrantLock {
	 private AtomicReference<Thread> owner = new AtomicReference<Thread>();
	 public void lock() {
		 Thread current = Thread.currentThread();
		 //这句是很经典的“自旋”语法，AtomicInteger中也有
		 for (;;) {
			 if (!owner.compareAndSet(null, current)) {
					 return;
				 }
			 }
	 }
	 
public void unlock() {
	 Thread current = Thread.currentThread();
	 owner.compareAndSet(current, null);
 }
}
```

不可重入锁的一个主要特征是它不允许同一个线程在没有释放锁的情况下再次获取相同的锁。这种机制需要谨慎使用，因为它可能导致死锁，特别是在复杂的多线程环境中
# 信号量和互斥量
1. 互斥量（Mutex）：互斥量是一种==`数据结构`==，用于保护某一临界资源在同一时刻只被一个线程访问。==当一个线程获得互斥量后，其他任何尝试获得该互斥量的线程将会被阻塞，直到原线程释放该互斥量==。互斥量常用于保护共享资源，避免并发访问导致的数据不一致性。
2. 信号量（Semaphore）：信号量是一个`计数器`，用于控制==多个线程对共享资源的访问==。信号量的值表示当前可用的资源数量。==当一个线程需要访问共享资源时，会先尝试获取信号量，如果信号量的值为正，则该线程可以访问资源；如果信号量的值为零，则该线程将被阻塞，直到其他线程释放信号量==。信号量可以用于实现资源的排队获取，避免资源的忙等待。
3. 同步原语（Synchronization Primitives）：同步原语是一组用于实现多线程同步和互斥的==指令或函数==。常见的==同步原语包括：互斥锁（Mutex）、条件变量（Condition Variable）、信号量（Semaphore）、读写锁（Read-Write Lock）等==。这些同步原语提供了线程间的同步和互斥机制，帮助程序员实现正确的多线程程序。

互斥锁只有两种状态：==加锁和解锁。当一个线程获得了互斥锁的锁时，其他线程就无法获得该互斥锁的锁了，直到该线程释放了该互斥锁的锁 .==

信号量具有一个==计数器和一个等待队列==。
==当计数器大于 0 时，线程可以继续执行；
当计数器等于 0 时，线程将被阻塞，并加入等待队列==

当计数器大于 0 时，执行 V 操作会增加计数器的值
当计数器等于 0 时，执行 P 操作会将线程加入等待队列，并将计数器减1
# Sychronized


用于线程同步，是一个可应用==于同步代码块或者是对象==。
同步是一种==高开销的操作，因此应该尽量减少同步的内容== （锁粒度减小）
通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可
对象锁的状态是记录在对象头中的**Mark word区域**中

为了避免临界区的竞态条件发生，有多种手段可以达到目的。
    阻塞式的解决方案：synchronized，Lock
    非阻塞式的解决方案：原子变量

synchronized，即俗称的【对象锁、监视器锁】，它采用互斥的方式让同一时刻至多只有一个线程能持有【对象锁】，其它线程再想获取这个【对象锁】时就会==阻塞==住。这样就能保证拥有锁的线程可以安全的执行临界区内的代码，不用担心线程上下文切换。
	在多线程编程中，互斥量（mutex）是一种同步原语，用于保护共享资源，防止多个线程同时访问同一共享资源而导致数据不一致的问题。==互斥量可以看作是一种锁机制，它提供了两个基本操作：加锁和解锁。==
	当一个线程==需要访问共享资源时，它必须先获得互斥量的锁==，这样其他线程就无法访问该共享资源了。当该线程完成对共享资源的访问后，它必须释放互斥量的锁，以便其他线程可以访问该共享资源

synchronized的三个作用
    原子性：确保线程互斥的访问同步代码
    可见性：保证共享变量的修改能够及时可见
    有序性：有效解决重排序问题
### 特点

**是非公平重量级锁 、依赖于**jvm实现
- synchronized是JVM内置锁，==基于Monitor机制实现==
- 依赖底层操作系统的==互斥原语Mutex（==互斥量==）==
- 实际上JVM内置锁在1.5之后版本做了重大的优化，==**如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、自适应自旋（Adaptive Spinning）==等技术来减少锁操作的开销，内置锁的并发性能已经基本与Lock持平。**

### 4.1偏向锁

Java 6 中引入了偏向锁来做进一步优化：==只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头==，之后发现 ==这个线程 ID **是自己的就表示没有竞争==，==不用重新 CAS**，不用进行用户态和内核态的切换==。以后只要不发生竞争，这个对象就归该线程所有。（比如重入锁重入了，那么就只有自己的锁）

    调用了对象的 hashCode，但偏向锁的对象 MarkWord 中存储的是线程 id，如果调用 hashCode 会导致偏向锁被撤销
        轻量级锁会在锁记录中记录 hashCode
        重量级锁会在 Monitor 中记录 hashCode

### 4.2轻量级锁

轻量级锁的使用场景：==如果一个对象虽然有多线程要加锁，但竞争不激烈，那么可以使用轻量级锁来优化。==
轻量级锁的应用场景主要集中在锁竞争不激烈、同步块执行时间短，以及无锁或偏向锁失败的情况下

    轻量级锁对使用者是透明的，即语法仍然是 synchronized

引入轻量级锁的主要目的是 在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁。
==通过CAS进行操作==
### 4.3 锁膨胀

如果在尝试加轻量级锁的过程中，==CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有 竞争）==，这时需要进行锁膨胀，将轻量级锁变为重量级锁。

### 4.4 重量级锁

Synchronized是通过对象内部的一个叫做 监视器锁（Monitor）来实现的。但是监视器锁本质又是==依赖于底层的操作系统的Mutex Lock来实现的==。

.==而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高==，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为 “重量级锁”。 

### 4.5 自旋锁

 线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。

    所以引入自旋锁，何谓自旋锁？ 
#### 不做线程切换的自旋锁
![[51d389dd592d4907b88415b9f0222e82~tplv-tt-origin-asy2 5aS05p2hQOW-ruivtOS6kuiBlOe9kQ==.png]]
虚拟机的开发团队也注意到在很多应用中，==共享数据的锁定状态通常只会持续很短的一段时间==，为了这么短的时间去挂起和恢复线程很不值得。于是他们想到了一种降低线程切换的系统开销的办法。

在多核处理器的系统中，可以让后面请求锁的那个线程先等一下，暂不需要放弃CPU的执行时间，看当前持有锁的线程是否会很快释放掉。如果等一会就能获得锁，就避免了线程切换的开销了。

为了让后面的线程等待，我们只需让线程执行一个**忙循环（busy loop）**，即所谓的**自旋锁（spin lock）**。
 所谓自旋锁，就是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，==就一直循环检测锁是否被释放，而不是进入线程挂起或睡眠状态==。
 
### 总结

CAS适用于轻量级并发场景，其中线程冲突的概率相对较低。在这种情况下，CAS可以通过重试来有效地解决冲突。**然而，在高并发场景下，大量的线程可能会频繁地尝试更新同一资源，导致CAS操作失败并重新尝试，从而产生大量的CPU开销**。相比之下，重量级锁在高并发场景下表现更为稳定，尽管其开销较大。
### 4.6锁消除

消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在==JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)==，
通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，
  通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个步方法，但我们将StringBuffer作为一个局部变量使用，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。

### 4.7锁粗化
锁粗化是虚拟机对另一种极端情况的优化处理，通过扩大锁的范围，避免反复加锁和释放锁。

 在使用同步锁的时候，==需要让同步块的作用范围尽可能小—仅在共享数据的实际作用域中才进行同步，这样做的目的是 为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。==

在大多数的情况下，上述观点是正确的。==但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入**锁粗化**的概念。==

锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁
其实都是具体情况具体操作
### 锁升级过程

各种锁并不是相互代替的，而是在不同场景下的不同选择，绝对不是说重量级锁就是不合适的。**每种锁是==只能升级，不能降级==，即由==偏向锁->轻量级锁->重量级锁==，而这个过程就是开销逐渐加大的过程。**

如果是单线程使用，那偏向锁毫无疑问代价最小，并且它就能解决问题，
连CAS都不用做，仅仅在内存中比较下对象头就可以了；
如果出现了其他线程竞争，则偏向锁就会升级为轻量级锁；
如果其他线程通过一定次数的CAS尝试没有成功，则进入重量级锁；

	虚拟机使用 CAS 尝试把对象的 Mark Word 更新为指向锁记录的指针。如果更新失败就意味着至少存在一条线程与当前线程竞争。 如果出现两条以上线程争用同一个锁，轻量级锁就不再有效，将膨胀为重量级锁
虚拟机检查对象的 Mark Word 是否指向当前线程的栈帧，如果指向当前线程的栈帧，说明当前线程已经拥有了锁，直接进入同步块继续执行。

![[20210818231343691.png]]
### synchronized同步锁为类
```java
        synchronized (SyncTest.class) {
		    .....
	    }
```
synchronized作用于静态方法时，跟使用类对象作为静态锁的效果是一样的
```java
class sss{
	public static synchronized void s(){
		...
	}
}
```
### 如何提高Synchronized并发性能？

    类似：Synchronized使得同时只有一个线程可以执行，性能比较差，有什么提升的方法?

减少锁竞争，是优化 Synchronized 同步锁的关键。==我们应该尽量使 Synchronized 同步锁处于轻量级锁或偏向锁==，这样才能提高 Synchronized 同步锁的性能；**通过减小锁粒度**（也就是锁的范围）来降低锁竞争也是一种最常用的优化方法；另外我们还可以通过减少**锁的持有时间来提高 Synchronized 同步锁在自旋时获取锁资源的成功率，避免 Synchronized 同步锁升级为重量级锁。**
### 使用Synchronized关键字需要注意什么？

==锁对象不能为空。==
    锁对象的信息是保留在对象头中的，如果对象为空，则锁的信息也就不存在了。

==作用域不宜过大（即减少锁的粒度）==
    如果把过多的代码放在其中，程序的运行会变为串行，速度会下降。把那些影响线程安全的代码串行执行；不需要线程安全代码并行执行，达到效率最高。

==避免死锁==
    避免让线程对锁持有并等待的情况出现。

## 如何避免死锁

1. **避免嵌套同步块**，避免锁互相等待的情况
2. 递归调用时，使用可重入锁
3. 使用Java的`java.util.concurrent.locks.Lock`接口提供了`tryLock(long timeout, TimeUnit unit)`方法，==它允许我们在指定的时间内等待获取锁==。如果在指定的时间内没有获得锁，那么该方法将返回null，这样我们就可以决定是否取消等待。
4. ==避免长时间持有锁：尽量减少持有锁的时间，将锁的范围限制在最小的代码段内==。这样可以减少其他线程等待锁的时间，降低死锁的风险。
5. 使用CoutdownLotch和semophore来实现多线程顺序执行，避免死锁出现（其实就是通过可用资源数量避免后续其他线程一直死锁）
## ReentrantLock 
ReentrantLock 的实现依赖于 java 同步器框架 `AbstractQueuedSynchronizer`（本文简称之为AQS）。

==AQS 应用一个整型的 `volatile` 变量（命名为state）来保护同步状态，马上咱们会看到，这个 `volatile` 变量是 ReentrantLock 内存语义实现的要害==。

## RreentrantLock和synchronzied比较

1. synchronized是独占锁，**加锁和解锁的过程自动进行**，易于操作，但不够灵活。
ReentrantLock也是独占锁， **加锁和解锁的过程需要手动进行**，不易操作，但非常灵活。

对条件的处理：`synchronized`配合`Object`中的`wait()`、`notify()`或`notifyAll()`方法可以实现条件等待的效果。`ReentrantLock`则提供了一个`Condition`接口，搭配`Condition`的`await()`、`signal()`、`signalAll()`方法，功能上更为丰富，例如可以分组唤醒等待的线程。

2.  synchronized可重入，因为加锁和解锁自动进行，不必担心最后是否释放锁；

**ReentrantLock也可重入，但加锁和解锁需要手动进行，且次数需一样，否则其他线程无法获得锁**。

3. ==synchronized**不可响应中断，一个线程获取不到锁就一直等着；ReentrantLock可以相应中断**。==

4. 性能：

- ==在低竞争情况下，synchronized 的性能通常较好，因为它是由虚拟机直接支持的，并且可以进行一些优化。==
- ==在高竞争情况下，ReentrantLock 的性能可能优于 synchronized，因为它提供了更多的控制和扩展性，可以更好地适应不同的场景。==

`synchronized`原始采用的是`CPU`**悲观锁**机制，即线程获得的是**独占锁**。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在`CPU`转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起`CPU`频繁的上下文切换导致效率很低。

`Lock`用的是**乐观锁**方式。所谓**乐观锁**就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是`CAS`操作。
# Monitor
synchronized的实现原理。

synchronized的monitor机制是指Java内部对象和线程之间的同步关系，以及线程对共享资源的互斥访问的一种处理方式。
Synchornzied原理，也叫做管程。
**每个 ==Java 对象都可以关联一个 Monitor 对象==，如果使用 ==synchronized 给对象上锁（重量级）之后，该对象头的 Mark Word 中就被设置指向 Monitor 对象的指针==**
## ObjectMonitor类
![[1be12aa99424490f97985494d59e1f88.png]]
在HotSpot虚拟机中，==Monitor是基于 C++ 的**ObjectMonitor类**实现的，其主要成员包括：

-  owner：指向持有ObjectMonitor对象的线程
- WaitSet：存放处于wait状态的线程队列，==即调用wait()方法的线程==
- EntryList：存放处于==等待锁block状态的线程队列==
- count：约为_WaitSet 和 _EntryList 的节点数之和
- cxq: 多个线程争抢锁，会先存入这个单向链表
- _recursions: 记录重入次数
![[20210815163352506.png]]

![[v2-ee554829ed472c73c5fb2461d5878b3e_720w.jpg]]
上图简略展示了ObjectMonitor的基本工作机制：

（1）**当多个线程同时访问一段同步代码时，首先会进入 _EntryList 队列中。**

（2）当某个线程获取到==对象的Monitor后进入临界区域，并把Monitor中的 _owner 变量设置为当前线程，同时Monitor中的计数器 _count 加1。即获得对象锁==。

（3）若持有Monitor的线程调用 wait() 方法，将释放当前持有的Monitor，_owner变量恢复为null，_count自减1，同时该线程进入 _WaitSet 集合中等待被唤醒。

（4）在_WaitSet 集合中的线程会被再次放到_EntryList 队列中，重新竞争获取锁。

（5）若当前线程执行完毕也将释放Monitor并复位变量的值，以便其他线程进入获取锁。

多线程竞争：[原文知乎](https://zhuanlan.zhihu.com/p/356010805)

# CountDownLatch
countDown 和 await
内部维护了一个计数器和阻塞队列

用于等待==多个线程完成一组操作结束==时候的使用，内部使用CAS对操作数进行操作
CountDownLatch 的初始值用于设定需要等待的线程数量。
- 将CountDownLatch的计数器初始化为：new CountDownLatch(n)，每当一个任务线程执行完毕，计数器减一 countdownlatch.countDown()，==当计数器的值变为0时，在CountDownLatch上await()的线程就会被唤醒。==
- CountDownLatch初始化一个全局计数器；如果想让某个线程处于等待中，该线程调用countdownLatch.await()，通过其他线程调用countdownLatch.countDown()减少计数器，直到减少到0，被await()挂起的线程恢复执行。可以实现1个线程等待一组线程执行完、实现一个线程释放一组线程、
多个线程释放多个线程的场景。
==latch.await();//等待计数器解锁完==
```java
new Thread(){
CountDownLatch latch = new CountDownLatch(10);//
new Thread(){
	repeat(10){
		Thread.sleep(1000);
		latch.countdown();
	}
}.start;

....
latch.await();//等待解锁完
....
}


```
# Semaphore（ˈseməfɔː(r）信号量

acquire()和 release

Semaphore也没有提供等待队列或阻塞队列的相关API。它主要关注的是许可的管理和计数，而不是线程的存储和调度。

==信号量在java层的实现，用于控制线程的执行，
当信号量大于0的时候，才能执行后续代码。==
==信号量释放后，有阻塞的线程会**按照阻塞顺序**恢复运行==

```java
...
Semaphore sem = new Semaphre(3);//信号量为3

new Thread(
	()->{
		try {  
		    sem.acquire();//获取信号量，此时信号量-1，如果是0，则进入阻塞状态
			// 模拟执行一些操作  
	        Thread.sleep(1000);  
	        System.out.println(Thread.currentThread().getName() + " 执行完毕，释放信号量");  
	        semaphore.release();  //释放。信号量释放后，有阻塞的线程会按照阻塞顺序恢复运行 
		} catch (InterruptedException e) {  
		    e.printStackTrace(); 
		    响应中断
		}
		
	}

).start();

...

```

# AQS（AbstractQueuedSynchronizer）

提供了一个基于==队列的同步器==，许多 Java 并发组件（如 ==ReentrantLock, Semaphore, CountDownLatch, ReentrantReadWriteLock== 等）就是基于 AQS 实现的。==继承AQS，实现对应方法，调用AQS的操作原语进行操作。==
是一个==简化的公平队列==，用于竞争同一资源的多个线程上，竞争的线程先进先出FIFO。基于==**同步原语来实现独占和共享锁**==

AQS 抽象类定义了使用独占模式和共享模式的一组方法供子类实现。==子类需要实现以下方法以自定义独占模式和共享模式的行为：==

1. 独占模式（如 ReentrantLock）：
    - `boolean tryAcquire(int arg)`
    - `boolean tryRelease(int arg)`
2. 共享模式（如 Semaphore）：
    - `int tryAcquireShared(int arg)`
    - `boolean tryReleaseShared(int arg)`
3. 可由子类实现以支持自定义同步组件查询：
    - `boolean isHeldExclusively()`

### 实现原理
AQS的实现主要依赖于一个==双向队列（FairQueue）和内部状态（state）的变更==。当一个线程尝试获取资源时，会先尝试通过==CAS（Compare-and-Swap）操作来更新状态==，如果更新成功，则将该线程放入队列的头部，然后执行资源访问操作；如果更新失败，则说明有其他线程已经获取了资源，该线程需要等待。==当线程释放资源时，也会先尝试通过CAS操作更新状态==，如果更新成功，则将该线程从队列中移除。

# volatile 

**不保证原子性。**

（可见性，线程的工作内存的操作的值可以在共享内存中读取）

1. （重要）**保证可见性**：1.每次操作都是都必须是主内存中最新的值。2。操作完都能马上刷新到内存中。
	-多线程共享变量，可能会存在脏读的现象，也就是，明明已经将数据更改！但是却会出现因为各个处理器内部缓存没有更新，所导致的脏读现象！volatile的存在就是为了解决这个问题！使用了volatile声明的变量会将这个数据在缓存行的数据写入到内存中。也就是保证可见性。规定是

2. volatile 只能保证对==单次读/写的原子性。 ==
3. **禁止指令重排序：**
**例如创建对象时候，初始化对象和对象指向内存地址的指令有可能被调换顺序（汇编编译优化），使用该指令重排可以初始化完对象，再让指针指向分配的空间的顺序正确，保证线程安全。**

（扩展，单例模式下双重检验锁->==可能导致第二个线程第一个if判断是否是空误判为非空==）

补充：指令重排序
![[b3k71htyyw.png]]

**性能优于sychronized**

### 问题1：那能替代sychronized吗?

不能，==volatile只能保证单次 读、写 的安全性，不能保证多次==
# CAS

==**原子类型实现的底层原理==。**乐观锁。**使用CAS叫做比较交换来判断是否出现冲突，出现冲突就重试当前操作直到不冲突为止。**


**CAS是一种无锁算法，在不使用锁的的情况下实现多线程之间的变量同步**。CAS算法涉及到三个操作数

需要读写的内存值 V 进行比较的值 A 拟写入的新值 B。

（比较和替换）。compare and swap。
#### CAS整个过程：

1. 读取内存位置V的原值R
2. 因为进行的是i++操作，假如：因此CAS操作的预期原值A = R、新值B=R+1（或者其他，这里假设是+1），进行CAS。
3. 获取V的原值R
4. 如果R等于A，更改成功，操作结束
5. 如果R不等于A，则没有更改。`但是获取当前时刻V的原值，将R重新设置为该值`。则预期原值A=R、新值B=R+1，然后在继续进行CAS。


比较到操作的状态值之后再执行操作，结果不符合则会进行 “**自旋操作**”，即循环获取等待正确比较结果。**每次比较并不是上锁，而是调用了原子操作**，跟就具体平台底层有关。

**当多个线程同时进行CAS操作时，只有一个线程会成功，并且更新V的值，其余的线程会失败。失败后可以选择不断的进行 CAS 操作，也可以直接挂起进行等待；**

```java
//例子
import java.util.concurrent.atomic.AtomicInteger; 
	public class CASExample { 
		private AtomicInteger atomicInteger = new AtomicInteger(0);
		 public void increment() { 
				int currentValue;
				int newValue;
				do { 
				  currentValue = atomicInteger.get();
				  newValue = currentValue + 1; 
				}while (!atomicInteger.compareAndSet(currentValue, newValue)); 
} 
public int getValue() { return atomicInteger.get(); } }
```
## ABA 问题

第一个线程从内存的V位置取出了A, 第二个线程也从内存的V位置取出了A, **先修改成B,然后又修改成了A**, 第一个线程在进行CAS操作时不会察觉到异常,虽然操作正常进行,**但该数据已经发生过变化**,某些应用场景下可能出现**数据不一致的问题。**

解决办法:添加版本号,执行操作时加上一个版本号,**版本号一致性可以进行操作**,否则失败。**每次操作版本号增加,因为版本号只会增加不会减少,所以不会出现ABA问题。**
**例如:  
1.线程1读取A(1)  
2.线程2读取A(1),修改成B(2),又修改成A(3),  
3.线程1读取预期值,发现预期值A(3)和变量值A(1)不同,不进行操作。**


某种程度上，CAS可以用来取代synchronized的[强制同步](https://www.zhihu.com/search?q=%E5%BC%BA%E5%88%B6%E5%90%8C%E6%AD%A5&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2733521727%7D)，它在底层的硬件和操作系统中实现，提升性能。其实整个java.util.concurrent包都是建立在CAS之上的，尤其是Java中大多数锁的实现基类AbstractQueuedSynchronizer，更是以CAS为基础，提供了一系列的独占锁、共享锁、[可重入](https://www.zhihu.com/search?q=%E5%8F%AF%E9%87%8D%E5%85%A5&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2733521727%7D)锁、[自旋锁](https://www.zhihu.com/search?q=%E8%87%AA%E6%97%8B%E9%94%81&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2733521727%7D)、读写锁等多线程控制手段

# ThreadLocal简介

ThreadLocal叫做线程变量，意思是ThreadLocal中填充的变量属于当前线程，该变量对其他线程而言是隔离的，也就是说该变量是当前线程独有的变量。ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。

ThreadLoal 变量，线程局部变量，同一个 ThreadLocal 所包含的对象，在不同的 Thread 中有不同的副本。这里有几点需要注意：

    因为每个 Thread 内有自己的实例副本，且该副本只能由当前 Thread 使用。这是也是 ThreadLocal 命名的由来。
    既然每个 Thread 有自己的实例副本，且其它 Thread 不可访问，那就不存在多线程间共享的问题。

ThreadLocal 提供了线程本地的实例。它与普通变量的区别在于，每个使用该变量的线程都会初始化一个完全独立的实例副本。ThreadLocal 变量通常被private static修饰。当一个线程结束时，它所使用的所有 ThreadLocal 相对的实例副本都可被回收。

![[20201217201331591.png]]

![[1368768-20190614000329689-872917045.png]]
==上图可看出ThreadLocal的get就是根据Thread取得Thread下的Map，ThreadLocalMap原本就在在Thread中，取出值的时候是用ThreadLacal本身作为key从ThreadLacalMap中取出。==
## ThreadLocal与Synchronized的区别

ThreadLocal<T>其实是与线程绑定的一个变量。ThreadLocal和Synchonized都用于解决多线程并发访问。

但是ThreadLocal与synchronized有本质的区别：

1、Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。

2、Synchronized是利用锁的机制，使变量或代码块在某一时该只能被一个线程访问。而ThreadLocal为每一个线程都提供了变量的副本

，使得每个线程在某一时间访问到的并不是同一个对象，这样就隔离了多个线程对数据的数据共享。

而Synchronized却正好相反，它用于在多个线程间通信时能够获得数据共享。